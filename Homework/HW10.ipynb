{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14fcfed-adf7-44f8-a01e-8912dff80507",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question I</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd54a7-c502-4e55-9d84-ab6d790f6dc8",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<ol>\n",
    "    <li>\n",
    "        Simple linear regression contains only one variable \\(x_{i}\\) and its corresponding \\(\\beta_{i}\\). It is represented with a model of the form:\n",
    "        \\(Y_{i}=\\beta_{0}+\\beta_{1}x_{i}+\\epsilon_{i}\\)\n",
    "        <br/>\n",
    "        Multiple linear regression, however, contains multiple variables and their corresponding \\(\\beta\\)s, which allows us to study more complex relationships that depend on more factors. It can be represented with a model of the form:<br/>\n",
    "        \\(\\begin{gather*} Y_{i}=\\beta_{0}+\\sum_{k=1}^{n}(\\beta_{k}x_{k}) +\\epsilon_{i}\\end{gather*}\\)\n",
    "    </li>\n",
    "    <br/>\n",
    "    <li>\n",
    "        When using an indicator variable, \\(Y_{i}\\) only has 2 possible values (without accounting for the random error of \\(\\epsilon_{i}\\), either <br/>\\(x_{i}=0\\Rightarrow Y_{i}=\\beta_{0}\\) or\n",
    "        <br/>\\(x_{i}=1\\Rightarrow Y_{i}=\\beta_{0}+\\beta_{1}\\)\n",
    "        <br/><br/>\n",
    "        When using a continuous variable, however, then \\(x_{i}\\) can take on a whole range of values.\n",
    "        <br/>Thus, \\(\\beta_{1}x_{i}\\) is also continuous.\n",
    "        <br/><br/>This results in a continuous range of possible values for:\n",
    "        <br/>\\(Y_{i}=\\beta_{0}+\\beta_{1}x_{i}\\)\n",
    "    </li>\n",
    "    <br/>\n",
    "    <li>\n",
    "        With simple linear regression, \\(Y_{i}=\\beta_{0}+\\beta_{1}x_{i}\\) is a function which progresses linearly.\n",
    "        <br/>When we introduce an indicator variable and have multiple linear regression, the model becomes \\(Y_{i}=\\beta_{0}+\\beta_{1}x_{i}+\\beta_{2}1_{\\text{group}}\\)\n",
    "        <br/>\n",
    "        With this model, we create two parrallel lines in the graphical representation, one for \\(1_{\\text{group}}=0\\) and another for \\(1_{\\text{group}}=1\\)\n",
    "    </li>\n",
    "    <br/>\n",
    "    <li>\n",
    "        By adding an interaction term, the model becomes\n",
    "        <br/>\n",
    "        \\(Y_{i}=\\beta_{0}+\\beta_{1}x_{i}+\\beta_{2}1_{\\text{group}}+\\beta_{3}x_{i}\\cdot1_{\\text{group}}\\)\n",
    "        <br/>\n",
    "        Here, \\(\\beta_{3}\\) represents the difference in slopes between the baseline group and the indicated group (so between \\(1_{\\text{group}}=0\\) and \\(1_{\\text{group}}=1\\)\n",
    "    </li>\n",
    "    <br/>\n",
    "    <li>\n",
    "        If the Multiple Linear Regression model is based only on indicator variables, then the linear form is:\n",
    "        \\(\\begin{gather*} Y_{i}=\\beta_{0}+\\sum_{k=1}^n(\\beta_{k}1_{\\text{group k}}) \\end{gather*} \\)\n",
    "<br/>\n",
    "<br/>\n",
    "        If \\(x_{i}\\) is in the group \\(k\\), then \\(Y_{i}=\\beta_{0}+\\beta_{k} \\), so the encoding of each group is binary, either \\(x_{i}\\) is in the group, or it is not in the group.\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b796755-f225-4652-8b74-a837dda43a6e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question II</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c8da2-25d7-49dc-a415-f2559057fc6d",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<ol>\n",
    "    <li>\n",
    "        The following are the outcome and predictors:<br/>\n",
    "        The outcome \\(Y_{i}\\) is the sports equipment sold<br/>\n",
    "        The predictor \\(x_{1}\\) is the amount spent on TV ads<br/>\n",
    "        The predictor \\(x_{2}\\) is the amount spent on online ads<br/>\n",
    "        <br/>\n",
    "        Without the interactions, the linear form would be:<br/>\n",
    "        \\(\\begin{gather*} Y_{i}=\\beta_{0}+\\beta_{1}x_{1_{i}}+\\beta_{2}x_{2_{i}} \\end{gather*} \\)\n",
    "        <br/>\n",
    "        With the interactions, the linear form would be:<br/>\n",
    "        \\(\\begin{gather*} Y_{i}=\\beta_{0}+\\beta_{1}x_{1_{i}}+\\beta_{2}x_{2_{i}}+\\beta_{3}(x_{1_{i}}\\cdot x_{2_{i}}) \\end{gather*}\\)\n",
    "        <br/><br/>\n",
    "        In this scenario, the effectiveness of each advertising campaign can depend on the amount spent on the other campaign. This is what is represented by the interaction \\(\\beta_{3}(x_{1_{i}}\\cdot x_{2_{i}})\\)<br/><br/>\n",
    "        Thus, the difference between predictions from both models is that in the model without interactions, we don't take into account the effect of the effectiveness of each campaign on the other.\n",
    "    </li>\n",
    "    <li>\n",
    "        To account for this change, we would have to change the linear form to:<br/>\n",
    "        \\(\\begin{gather*} Y_{i}=\\beta_{0}+\\beta_{1}1_{[x_{1_{i}}=high]}+\\beta_{2}1_{[x_{2_{i}}=high]}+\\beta_{3}(1_{[x_{1_{i}}=high]}\\cdot 1_{[x_{2_{i}}=high]}) \\end{gather*}\\)\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec96a2f-a344-489a-8491-9bc5bd65f199",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question III</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad31d9-9ad3-4d03-b7bf-efa7130bfc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53367c86-9bbb-4392-97dd-5d7bb88d088f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2919e29-0f24-456a-9b55-d7487dd29d54",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question IV</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79fcc290-86cb-4e5d-b9e7-c6a619e340d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:26:06</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     23:26:06     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        23:26:06   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630b51c-16c5-4169-b913-59409d6b9035",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<p>\n",
    "    As seen in the previous homework, \\(R^2\\) is the proportion of variation in the outcome that is explained by the model.<br/>\n",
    "Here, \\(R^2\\) is equal to \\(0.176=17.6%\\)<br/>\n",
    "\n",
    "However, p-values measure the significance of each predictor in the model, with a low p-value suggesting strong evidence against the null hypothesis, i.e. that a predictor has a significant effect on the outcome.\n",
    "<br/>\n",
    "<br/>\n",
    "This means that even if some predictors in the model have very high significance with a low p-value, there can still be a large amount of variability that could be accounted for by other factors not in the model.\n",
    "<br/>\n",
    "This way, it is possible to have a low \\(R^2\\) even with many of the coefficients havingvery strong evidence against the null hypothesis of \"no effect\".\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4bdd07-23a6-4917-892f-69c19fc31782",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question V</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29233a09-9bdb-4474-a250-45da9852413f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23d7945-8044-48cf-8d3d-d54f10db4716",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Code block 1</h2>\n",
    "<p>\n",
    "This first block of code splits the pokeaman dataframe into two dataframes: pokeaman_train and pokeaman_test, by using the train_test_split() function, randomly distributing the rows into the two new dataframes.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e3f29ee-4452-4bd6-92f3-6579782b8e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:26:14</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     23:26:14     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        23:26:14   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8465ad4c-ea9a-4876-8839-431d10a827cc",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<h2 style=\"color:green;\">Code block 2</h2>\n",
    "<p>\n",
    "    This block of code fits the data we have with the linear form:\n",
    "    \\(Y_{i}=\\beta_{0}+\\beta_{1}x_{\\text{attack}}+\\beta_{2}x_{\\text{defense}} \\)\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c36b515-eb90-421e-8df4-6dddf80eea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519905\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba498489-9af7-4b42-af35-a84a7784965b",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<h2 style=\"color:green;\">Code block 3</h2>\n",
    "<p>\n",
    "    This block of code first uses the model made using the pokeaman_train dataset, which is our sample. It uses said model and its linear form to predict the HP values for the pokeaman_test dataset.\n",
    "    <br/>\n",
    "    Then, it extracts the actual HP values from the pokeaman_test dataset.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    Finally, it calculates the in-sample \\(R^2\\) and the out-of-sample \\(R^2\\)\n",
    "    <br/>\n",
    "    Both of the \\(R^2\\) are pretty low, meaning this model does not explain a large amount of the variance in both datasets (15% and 21%)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "525dbfaa-6c01-4ca0-bebd-bf8bacf5816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:26:19</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1182</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     23:26:19     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1182  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.665  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        23:26:19   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1182      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.665\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "704b9699-9605-480b-baec-0f5179d32ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAB1CAYAAAC7zGCaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHi0lEQVR4nO3dd3xUVd748c+900t6SIcQSggkgdC7AUGKFEFXbAu4uquuK4JuEdfdVVdWLLvqs8/an7Xt4g/XtQsiKEWkE3ovCQklvU4yfe75/REYDaFkIDQ979drXjB3zpz7vfdk5n7n3HvPUYQQghBERUXx9ttvM3HixCbLP/30U6ZPn051dTX79++nX79+VFdXh1K1JEmSJElSyPShvmHq1Knceeed/P73v6dv374oisL69et58sknmTZtGgArVqwgMzOz1YOVJEmSJEk6mRJqz0wgEOCpp57iH//4B6WlpQDEx8czY8YMHnroIXQ6HUVFRaiqSkpKygUJWpIkSZIk6YSQk5nvq6urAyA8PLzVApIkSZIkSQrFeSUzkiRJkiRJl5oa6htKS0uZOnUqSUlJ6PV6dDpdk4ckSZIkSdLFFPIFwLfffjtFRUX88Y9/JDExEUVRLkRckiRJkiRJLRLyaaawsDBWrlxJTk7OBQpJkiRJkiSp5UI+zdS2bVvkZTaSJEmSJF0uQk5mXnjhBWbPns2hQ4cuQDiSJEmSJEmhCfk0U1RUFE6nE7/fj9VqxWAwNHm9qqqqVQOUJKn1rFu3jqeeeoq8vDxKS0uJjIykQ4cODBo0iL/97W/Bcu3btycrK4vPP//8EkZ7bq7k2CVJOjchXwD8wgsvXIAwJEm60BYsWMDEiRMZNmwYzzzzDImJiRQXF7Nx40bmz5/fJJmRJEm6kshxZiTpRyI3N5ejR4+yZ88e9Pqmv2M0TUNVvzvrfCX3blzJsUuSdG5adM3MiZF+T/z/TA9Jki5PlZWVxMbGNktkgCaJzPctWrSIXr16YbFYyMjI4I033mhWpqSkhLvvvpuUlBSMRiNpaWk8/vjj+P3+JuW8Xi9z5swhIyMDk8lEmzZt+NnPfkZ5eXmTcu3bt2f8+PF89NFHdO/eHbPZTIcOHfj73/9+Ttt96NAhFEXh2Wef5emnn6Z9+/ZYLBaGDRvGvn378Pl8zJ49m6SkJCIiIpg8eTJlZWVN6njvvfcYNWoUiYmJWCwWunbtyuzZs2loaGi2vtdff5309HRMJhPdunXj3Xff5fbbb6d9+/bntD8kSWoB0QKqqorS0lIhhBCKoghVVZs9TiyXJOny9POf/1wAYsaMGWLt2rXC6/WetmxqaqpISUkR3bp1E++884748ssvxY033igAsWLFimC54uJi0bZtW5GamipeffVV8dVXX4knnnhCmEwmcfvttwfLBQIBMWbMGGGz2cTjjz8ulixZIv7v//5PJCcni27dugmn09lk3cnJyaJdu3bijTfeEAsXLhS33XabAMSzzz571u1MTU0V48aNCz4vKCgQgEhNTRUTJkwQn3/+ufj3v/8t4uPjRXp6upg6daq44447xBdffCFeeeUVYbfbxYQJE5rU+cQTT4jnn39eLFiwQCxfvly88sorIi0tTQwfPrxJuVdffVUA4oYbbhCff/65mDdvnkhPTxepqakiNTX1nPaHJEln16JkZvny5cLn8wX/f6aHJEmXp4qKCjFkyBABCEAYDAYxaNAgMXfuXOFwOJqUTU1NFWazWRQWFgaXuVwuER0dLe6+++7gsrvvvlvY7fYm5YQQ4q9//asAxM6dO4UQQvy///f/BCA++OCDJuU2bNggAPHSSy81WbeiKGLLli1Nyl5zzTUiPDxcNDQ0nHE7T5fM9OjRQwQCgeDyF154QQBi4sSJTd4/a9YsAYja2tpT1q9pmvD5fGLFihUCEFu3bhVCNCYoCQkJon///k3KFxYWCoPB0CSZCWV/SJJ0di06zZSbmxvsms7NzT3jQ5Kky1NMTAwrV65kw4YNPPXUU1x33XXs27ePhx9+mOzsbCoqKpqUz8nJoV27dsHnZrOZ9PR0CgsLg8s+//xzhg8fTlJSEn6/P/gYO3YsACtWrAiWi4yMZMKECU3K5eTkkJCQwPLly5usOzMzkx49ejRZduutt1JXV8emTZvOafuvvfbaJqfTunbtCsC4ceOalDuxvKioKLgsPz+fW2+9lYSEBHQ6HQaDIfh9t3v3bgD27t1LSUkJU6ZMaVJfu3btGDx4cJNloe4PSZLOrEV3M23btq3FFXbv3v2cg5Ek6cLr06cPffr0AcDn8/HQQw/x/PPP88wzz/DMM88Ey8XExDR7r8lkwuVyBZ+Xlpby2WefNRui4YQTCVJpaSk1NTUYjcYzljshISGhWZkTyyorK8+0eacVHR3d5PmJWE633O12A1BfX8/QoUMxm83MmTOH9PR0rFYrhw8f5vrrrw/ujxNxxcfHN1t3fHw8BQUFweeh7g9Jks6sRclMTk4OiqKcdeRfRVEIBAKtEpgkSReewWDg0Ucf5fnnn2fHjh0hvz82Npbu3bvzl7/85ZSvJyUlBcvFxMSwaNGiU5YLCwtr8rykpKRZmRPLTpVkXUhLly7l2LFjLF++vEnvc01NTZNyJ+IqLS1tVsfJ2xPq/pAk6cxalMx8/xeFJElXpuLiYhITE5stP3Ga5ETiEYrx48ezcOFCOnbsSFRU1BnLzZ8/n0AgQP/+/c9a786dO9m6dWuTU03vvvsuYWFh9OrVK+Q4z8eJyXRNJlOT5a+++mqT5126dCEhIYH//Oc/PPjgg8HlRUVFrF69usn+DXV/SJJ0Zi1KZlJTUy90HJIkXWCjR48mJSWFCRMmkJGRgaZpbNmyhb/97W/Y7XZmzpwZcp1//vOfWbJkCYMGDeL++++nS5cuuN1uDh06xMKFC3nllVdISUnh5ptvZt68eVx77bXMnDmTfv36YTAYOHLkCMuWLeO6665j8uTJwXqTkpKYOHEijz32GImJifz73/9myZIlPP3001it1tbcLWc1aNAgoqKiuOeee3j00UcxGAzMmzePrVu3NimnqiqPP/44d999Nz/5yU+44447qKmp4fHHHycxMbHJ9Tqh7g9Jks4s5BGAT9i1axdFRUV4vd4myydOnHjeQUmS1Pr+8Ic/8Mknn/D8889TXFyMx+MhMTGRkSNH8vDDDwcvfA1FYmIiGzdu5IknnuDZZ5/lyJEjhIWFkZaWxpgxY4K9NTqdjk8//ZT/+Z//4V//+hdz585Fr9eTkpJCbm4u2dnZTerNycnhZz/7GY8++ij79+8nKSmJ5557jgceeKBV9kUoYmJiWLBgAb/+9a/56U9/is1m47rrruO9995r1kt01113oSgKzzzzDJMnT6Z9+/bMnj2bTz75pMkFxaHuD0mSzizkEYDz8/OZPHky27dvb3IdzYmuWHnNjCRJ5+OHNoJvTU0N6enpTJo0iddee+1ShyNJP0ghz5o9c+ZM0tLSKC0txWq1snPnTr755hv69OkjbyeUJOlHraSkhBkzZvDhhx+yYsUK3nnnHYYPH47D4Tin03iSJLVMyKeZ1qxZw9KlS2nTpg2qqqKqKkOGDGHu3Lncf//9bN68+ULEKUmSdNkzmUwcOnSIe++9l6qqKqxWKwMGDOCVV14hMzPzUocnST9YISczgUAAu90ONN5eeOzYMbp06UJqaip79+5t9QAlSfpxOXTo0KUO4ZxFRUXx2WefXeowJOlHJ+TTTFlZWcFB9Pr3788zzzzDqlWr+POf/0yHDh1aPUCAl156ibS0NMxmM71792blypUXZD2SJEmSJF15Qk5m/vCHP6BpGgBz5syhsLCQoUOHsnDhwnOe1fZM3nvvPWbNmsUjjzzC5s2bGTp0KGPHjm1yZ4AkSZIkST9eId/NdCpVVVVERUUF72hqTf3796dXr168/PLLwWVdu3Zl0qRJzJ07t9XXJ0mSJEnSlSXka2Zqa2sJBAJN5jOJjo6mqqoKvV5PeHh4qwXn9XrJy8tj9uzZTZaPGjWK1atXn/I9Ho8Hj8cTfK5pGlVVVcTExFyQZEuSJEmSpNYnhMDhcJCUlNRk0MlTCTmZufnmm5kwYQL33ntvk+X/+c9/+PTTT1m4cGGoVZ5WRUUFgUCg2cRt8fHxp5y7BWDu3Lk8/vjjrRaDJEmSJEmXzuHDh0lJSTljmZCTmXXr1vHcc881Wz5s2DAeeeSRUKtrkZN7VIQQp+1lefjhh5vMi1JbW0u7du2IiIgIvifZoKO9+dSz1UrnyRLHwFFDiYhri/fgt+w+3IDVfPzPTPNSciCfBo+vxdVFduxNr16diE5KZMP81yksbTjn0MzRiSQlx3LiL8ddVcyxoxWc93nWS6Q1940tri3x8ZHH942gvvQwpWW1rRWqJElSyHyaxuKjpS2aeDXkZMbj8eD3+5uv1OfD5XKFWt0ZxcbGotPpmvXClJWVNeutOcFkMjWbEA4aE6ITyYxOVTGcpctKOkfeGvatXY1B1airrEZntuDWHd/XQiMQ0ELa9+5j+9jpLiXgclBX4zqvdhPOWqqOuIPJTMDrQn8F/x205r7RHFVU+eqD+8bndsvPiCRJl4WWXCIS8rdV3759Tzkk9yuvvELv3r1Dre6MjEYjvXv3ZsmSJU2Wn5jYTroMCT915aVUlpbj8/tx1zuor61tfNQ5CGih9YMEPA1UFR+jtsZx3j0omtdNw4lYamtxubxnf9NlrDX3jd/jarJvPCH0nkmSJF1qIffM/OUvf2HkyJFs3bqVESNGAPD111+zYcMGFi9e3OoBPvjgg0ydOpU+ffowcOBAXnvtNYqKirjnnntafV3Sj0eTg7+i4I224reb0Ix6hE4FVQFNoAiB4tdQ/AHU4//q3H50Ti+K77t5yC7lpeVCVfCHmQmY9MG4VW8AvcONEtAuaWySJEkXQ8jJzODBg1mzZg3PPvss//nPf7BYLHTv3p1//vOfdO7cudUDvOmmm6isrOTPf/4zxcXFZGVlsXDhQlJTU1t9XdJ3vn+wP93BUAABiwHNYkAc7wZU/Bo6jw/V7T/je8+6buW7IM71YCwAzdT4J676AnCiV0hVcLaLJmAzonoDuJIiqE+PR/UGUDQNhGh8s9K4dqE0vgdFQagKQqciVAV9vQdrYSXGigYUIdA1eDGV1aF6Q09yQu1ZCdhMuBPCQFGp79QGV9solIAWjFvoVIzl9UTlFWI5Uo1ypV4YJEmS1AKtMs7M5ayuro6IiAgiIyOD593aGvV0+BFdAHyqxOTEgV7oVBRNNP6C9wdANCYovqjGngpFgOIPHO+d0FA0DUUTCEXBnRhBTe928L3zmY2JiIKprI6IbUcx1LpQ3T5UXwAlIBoThdPFadTht5up6dkWZ2o05mO12PLL0bl8mMrrUd3fnfo4U5Kg6VVcyZE428dQ3zmuMT6lMdFS3X7QHX93QCD0KuYyB5EbDqFv8KD4tOMJDcH3BRMYnYrQKQiDDs2oxxNrx9k+Bm+UFQXQDDqETsVQ6yJi21FUpxfr0WoInOUjpiq4E8LxRVkRgBpo3NcBixF3UgTuhHA0vQ6EaGwrTSAMOlS3D6EqWA9XE77taOM+Fo1tI/Qqjox4anu0JeW9jRirnWeOQZIk6TLj0zQWHC6mtrb2rMO+hNwzs2nTJgwGA9nZ2QB88sknvPnmm3Tr1o3HHnsMo/HHkyRcCTS9iqtdNH6rEdXjR/X6Uf0arqQI6rKTG3sboFl2oAhQfAGEqjT2SpxMAX29h7ivdqOv8zQeRAF0KppRR0NqDBXD0htP2fBdb4vi1xoPuscTJxQQet3x0zuNvR/WQ5W0+XoPDR1iqe6TimYygAKWoipsByvQOz2YSh2nTWg0k57q/mnoa11Ery3AbzdhrHai+DU0kx7Fr2EtqmpMjo73AJ2yruM9NIomwK81e9lcUkfEjmPB7TuRBHqjbY1xG1QMdW5MpQ50Lm8waRTH95Fm1OO3mfDG2tEMKrrjvVmaXgVFQfUFMBfXEr22oDFWnYqmU0GAoc6FqaL+uxhPEX7kpsPUd4rDH26WyYwkST9oISczd999N7NnzyY7O5v8/Hxuuukmrr/+et5//32cTicvvPDCBQhTOheaQUf58C4420Wjd3rQjPrGAyVgrHYSt2Q3qi/Q+EtepyJOHEQ9Pgw1TnTO4z0hqoKmVxE6HeiU46eUBDqXD/UUB3kAU0kdUZuL8NtMBMx6hL6x10Iz6NCMOoRe13gAPt7zo3r9qG4/eqcXfa0TJSCwFVYBEDDp8UbbqO8ST/nIDIReJe7rPegavE1OHWl6Fc1sIGAxYCqtwxMXRnVyexS/RuyKfcH6mmilfkkF0Lt86F21mI/VEr7jGJpZT123JDwJ4Xji7Ai1sWdH0UTj9noD6Bs82DZWYimsRO9q3YtulYCGEhBoBl2r1itJknS5CTmZ2bdvHzk5OQC8//775Obm8u6777Jq1SpuvvlmmcxcJgJGHZVDOuFOiiD5v3kYao7fNq82noJQ/FrjBa4tqUwT6LwBIHDWoicogOINYPQ27RE4U+5wulh0Hj+W4trGXoo1+VQN6kDl4I4EjPrgtSBCAUUIVLcfnduHvs6N/UA51vwKDLWtO2TA2ZzYDtXtJ3JTy+YQuyAX6YrGfSJO1bMmSZL0AxJyMiOECE40+dVXXzF+/HgA2rZtS0VFRetGJ4VMAAG7ifJh6XhjbCR8tg1Djeu7g6UmULwtT0pa2/kcVhVA9fiJXbYP4Lu7jqDxepLT9BJdqkP5JU8h1MYLlk/XeyZJkvRDEXIy06dPH+bMmcPIkSNZsWJFcALIgoKC0w5kJ114AvCHmWno1Iba7GT0DR6SPtqCvs596Q+qrej726IEtFA6i350fGFmNJMe1dN8kEtJkqQfkpAHzXvhhRfYtGkT9913H4888gidOnUC4L///a8cyO4S0Qw6HN0SOXJTbxxd4oncXETiZ9talsioesIiI4I3JCkGMzFJyUSEWy902AAYbJHEJSdhNjbm1abwaOKSEzEafiCjz+pNhEXYW1xc0RuJTko57/0vgMqrOqP4NYyV5z7NQasymAkLt53yJb3Zjs3WfOTu0zHaIzCbQv4tdkY6sw2r5Yd/A4OiM2I/TTu0vBIVW1Rk8MbAU6ykyffK5URnDqNNSjJWswl7bAKx8bGnvMdBurKEfMTo3r0727dvp7a2lkcffTS4/Nlnn+Xtt99u1eAulmhbBCPio7HoDFyVkkxKK18wGWWJYHxqKmPbtqVf5Hl+iZwkYNJTMjaLykEdiP32IKkL8hnXoRcWTUeX3Al0SDnzQdFoT2byXbdiMTZ+mlVzBBljpzLp+lxathcUUnqNID0t6pzit8amMPKXvyWnSyIA4YkdmDjzITq3izin+vT2WAaPGnb6L9nvUw10GDKBKTPvJzXejM4cw6CbfsZPfnkvvXp2RKe3kDV6CtfffTe9e3c6+xeezkjn3AlMuudeBl2Vg14FNSKZ7F4Z6IHE7FHc8ptfc8Pdd5LeIfaUVST2HMt1t0wkKenc9ucJmtlAwGqgzdK9TW5pv5R0kSlk90w//nel0Cl3DG1jGxO9xL4TGTkiq8V1dZk4jX7dklsvOMVA9wk/pVvHaNCZ6DL8eqbcfy9J0QZUo5U+k2/nJ7/8JQP6Z6AzmMgcfRM33f9z2lj06MOSGD71F9xw1y/o2iUJQ0QyuT/9BTfccxeZGcnoLTEMmnIHk++6i6yuyWf9gaGPTGb4tHuZcP3VGBWI6dyPiXffx8TbbiAmwow5NpVRd85i7LiBqECb7KFM+uV9jLvpOiLtJtoPHMPke+9nzOSR2Ew6EnJymfTLexl9/ShsJhXVGseIqbcSbT2PHwyWaMbc8wuiT5NQ6m3RXHf37VhMJ3+LKCT1upouHVr4+VZU0oePITmq9b43u0/6GSPGXEVUWDjxXYdwy2/uJbqFOaw5tgMDcnsej01Hcs/hTP7lfeQO69WYuCk6Og2/gZEje16WidwPWav9tDGbza1V1UVnN1vIirJR6tPTPSKcmspyFEsE6XYzFfU1HPPryYq0IzQNLeBlY1UtHaJiSTCqHKyqoMDtIyMmjkhVoAo/hz0aZr+L/W5BjygbTmFG56lhcZkDTWig6OkVG40RBb/fyeYaF9mx0ZhRCPhd7Kn30T02Cn3Aw5aKKlyqkV7REaAo1Dtr2eEI0CV3FL6itez0+PFFWkj5fxvRN3jQR6WQ0bcXW75YRlK3vngb8ojoOYEIg4rOV8qqxatoN3AMGZ3iqdq/gc3bqrHGd+aaqXdSsW8D677dyrYN22mfc+IuIQMdB15DZtckjm1dyaaNe/n+jATRaT255tZphNV2J+yLBWzZVkzO6PEkx5nZu2wBe/PLmuxrW3w6A8fkYha1bFy4gJLCHezZfwzT8Q9++d488ovGBr8I7IldGDQ6F7X+KGsXfomDMHpeM5akKB07vlqIM7Ibfft3xVNZwNql68kYezOjx/UmPDKS9YsWoG/Xj779s3AUbWPN0rV4vz/mi9CoOZxP4OrhxEQYOFLt5+i2VRSIWG6cPoWium8Y0i+Oj99Zwrg7b6Jw77NU1J9+CoTI9KsYMbgdH/3zPRSTCcUcQ78Rw7A5dgIKkW0z8RcuZ92xNMZMvIaCF/4f308zItr24Oop44lq2IfRqMfSJo1BY0Zg9lWyZuFC6pRohl5zFagGnEV5rFu7u8n6E3vk0qdvFxxlB1hYmk+7tI4M93ZC9ZayauEyXP7vbbtqpNPgUXTLSKb6YB5rlm8kMmMQPbolodfr2fPtFzhsGfTKbotqMHBw/QrsXa6ifZKNo1tWsrfcREa8n02b8sm6ejhF335NdfDuNz1drxpG2caVVNZ7Se51FRbHUeJ652Kp2gqKQnzWVYy+bRr+XR349suPcSg6EjMHMSGuB7sWf8TBouom22Zp057BY0Zi8lWwasEXKDojHYaMI7JHDWs/+YhAQg4DB2bjqz3Mmi+WkzrsOpIjBJ76CjYsXo4a15WBIwYhaopYs2gJDnfT85P6iAQyO9n57JMyECqVhw6iDh9CVJiO4lovBXkrqE7sxPgbb2HvjrmUH9qHZeRtRBj1VDpr2f3tUmI6D2XEDaMpfHkBhzZ8zUFLBtdNGU/lwiKyUwJ8tqiIideN4uD+N3Gd4cyf8NZTcKiUiUM7o/9oKQ2lBWz8uo7uE3/OoH47WbS6lKIjFQzr1hF1wRrqjuxjw1fl9L35F/Qp3Mm2skOs+ng7A++YReaBI6SMG8OhT14medw9pKdtYfOeoxypC6dbRjLfbjrcdOWqiYzcsaR3iqd8z1rWbyigz7hxWFCg/hCrlubRcehYOnVKIjnG3iwxU/QWuo0YT6fUWNpEWNCbouk/fizxEToOrv6KEl8so26ZRqQji7AFi9m6p4p+48YSY1fZ881C9h0o/X5tJOYMY8xt03FltWfVkk/xx3enYcdKynVJ9Oxi55gjhqzMBAJ+F9u//pIaNY6B11yNOVDB2oWLqKpzN4kvpc81DBs5hJrtizCoPg5uXEvFsI7fra/HEPr260ZN/ibWLNtC2wEjycpsS03hNvLW7WfADVMZ0icKe2QMm9YWcM3kq8n7+H2qK8oQAuxtMxl49dXYKgIs+3qzPAt+Ef1A+vLPkxAccXrpF23jiNODwWjnqtgw8mtq6RDdhg5hYeg1PwlmPTaTjU6RMXQxBdhS46JvfCxWRaFjZCQet4PN1XU4AgqZUeHEWcNINan4hEJSeAxDEhJIt5lA1dMlKpyyukp21TkRio4ukRFUOCrZWeekW5s4As5qyrHQO9KKQWega4SdfZUV5Dd4AIHf56G6WxKlYzMJ21eK3uk59S8+nYlO/ftRtWMNpi5DSGtjoqE0n00r19Jx1PUkhJnRGwTblq+g7fAbSIls2pNjTunJ6NHZ7F67kaxrbyQuomnSWl20g+15O9m14nO2bc0nNnsY3dt6Wbf2EENvnIjtpHRZ+F0c3PANR11x5I7scZaG0dN38hTce5dTYerCoEEZtL9qMp3CKlnx2SKq6z34GirY9s0y9B2GktkpjJ3fLuXwnq18s+BLHGocY2+ZSOHG1YTnjKXbyb8GRYCqwwXUOTwABLy1FO4+gD68DVUF+/B63AjVgNlmIyK5PdFnHGhRIaFDF6oObkFp043eA/tgFHVs23qQlM5pjT1Fikpa/7HkjhhAzeHDzb7o6o7tYuvGnexZ/gU7dx2l+4Sb4MhGDnuSyL06C709lpxBOexb9jk7dxU23RRFwekq5aut3/BNdhp1vbswtk0PqnauxthpKO2TTv6xIXCWHyJv+RraDbuB9jFGIjv2oHOcYPWChZRWOglvn0V6ko41ny+gpNxB7eE9bF67nb7X3YA5EKDr8JFEJ3Ulp0c7PIHA96vGlpJNRk5P+g8fQNbAfqjOSrZuO0TbzqnoEJTvWc+unbvY8uVn7N1fCopCwFnK7oMu+g/v22zvJvYYQZKtim0bt+P2BUA14T66nSPOOPr2TsPvrGLnyq8JpPSlV1ZHOvbpR+2etTiietC7VzbDp/4U98F1uGJz6Ne7Y7P6LfZYTFoN9X4NND8VhQXUN/iO/5n4cfrMZA8ehPPIfpweD2WF383+rvmcaJZ4evTvSumBfDw1ZRTuO4ylTRvKDxzAcfgQ3thMRl4/nPKD+znb9fcBZy1Hi47hP/6rwV1XQ3Tn3nRMgsNFVfgaqik5XEzg+HXdnhoH8VkDSIkIcLSkirKDe6h1G7EGqigtO0phfjm9J00lJcxJaXkdIKgqryM+uc0p119feoC8FRvoMvpGUmLDyOjXi6MbVxPdewSdO2UydEg7Nq9YizA2Py1oS+nFoJ5R5H27BdVsBKFRvn8z27YcZvAN43Ad28PWTTvY9c3nbN12gIAIULJ7Pdt31jBs0mjMTb4vBKW71rJ71242LfqMfQdKCZgS6T2wK536jyDK7CeyU18iAgXsPaYjd8wgBt30M4zVuynVUsgdlt0svmNbV7J79142fLmQw+UnzQpvS+TqySPYvXgh0X3H0zk1DFfVETYtW0nioOtoG+li64oVFO1Yy7dfrkTY25LcLoEOfa7imp9MIDIskr4jB7L325N+NEkXhUxmjqt11rGyrJxyXwCDXk+Y3kCK3U6Vy4VHE7h9fpx+P04N7HojLp+Xao8HoerQK+Dz+yhxe3EFAtS4HDj1NvrEhHGorh4/UF5fw9aKcgqPT27o8rqp8PhxBgJogMvnptzd+NyiU6nyeKn2+LAYGj/ddW4n1f4ATk0g8LMzfyObkiKIX7iTqPWHvrtFWRNoAnQ6FVUHgYCG31VJVXE1LqfAFhlH77HjyRnYl+i4WCx6FXdNGRXlpdR5FGxGHSBQj8+YbIqMJSI8krTMLpTu343X1/TOGBHw4fN6CHg9+Hx+LOHRNFQeo+JoMZo5DMNJyUxc9iAGjRhBx46phEU0jugoBOi+dw5HCFBUFRQj9jAD5SXHqCiuwhZlxx4dQXVRIXVVFdTWC7oMHUPf3MEkJcdhsZjxe9wEAn68bjeqwUxEdAzJ3TLxFe+jxnmGu3oUAJXE7lcxuF80X773OY5j21n69V669euJr7qcen8AFB0m86mu7RA462sx2yKpP5pPYvd+hFl0eD0eNBFsHI5u+5aVX64gpksmVsNJNQR8+Lw+/B43fn+AsDALFcUlVB6rwBrRmIjVHjtIaXkNjjonmk7FbzNS3ymO8pEZ7Brdnr294ghXjAzfXI6pxElNWQlOVwCDqWkipjOH03v0BHoO7EdsbBvMFh0EPBQd2I/DUYfb5YOAjyPHn/v0CfS/9lq6980hKjYGre4IBTV2hl03goptq3F5vrdvhZ+j+YfpPn4sfYeOol2sRllNHT6Pt3EAaAGa34PP68d3fFuF0KgoyqestBTV2LyX92jeIvYVmxg5fTqdk6Ig4KSk8DBVxdUY7RGkDxpF3+FDSW6bhN1iIuB1UVtbRX2Dh7CoWKJiI4lL64bFfZSyyvpm9ft9TlBN6IIXj/Hd1eaKirdiP5+//grVtg7Ef7/hFEBVqdq3nk9efQN7px6YzCba9R9DrzQXX36ykqj07qjHNvHVB18S2zUHs0lFUXXoT/5wfJ/y3b+qHnYveY8vFmyhY/dOzcqoOh9bP/s3X32dT+fMJIyRiYy8dTL7F86jqMZKRmYc6z54h33lejq3a7xJw2Qx4m7wNFut3hZF3zETyOnfm+iYWExmFW99OdUl1bi9KrawaAKOUspKjlFd3fxaLJ09HG91CVXFhdTUeTAldmbw6DFk5mQSHRkNmh+f14vf58Pn8xPeNoNBY8bQLTud8KgodCcdkTSfF5/vu89EYd4aIrKG0bdHJLu25SOEn9qKCmprqjGHRxPdpg3RqelEGxwcKa5uFp/m8+D3+fC6XY2T3orG4SlUBRSTBSNOKopLqHH4scbEkzPyWnoNGkB8bCxGkwGvx0MgoOHxePD7XNQd2cWX897DYe9Apx4DyOnVmY59e9M+qz8JbS7OdYdSo9a9gu4KpQmBN+Bjf52LMHsUPlc9e50mzDoVn9+DS1OxCoFfaPiFRrnTQZvoKEYmCmrra2nQwK9paCdGUREBDjb4GRdrZJXLi10viLRF0B0ztc46tjp8+DTRZMwVv3bi3YKDjgb6xiUSUHTsK6tCYMSnfXew0KxWascNIC7/EOaS2ibz7vicNRw65uPaO2/HEulg0ZEG4jxeNCHw+7wIRYfJpKeywYnf40bTNIwxnRlz6zTsvkJW1bjwaIXo2t/AkKtLWZe3mR2HsrFYrfgcxbgCJ/+sFFQVH6PX0An0cH/J/j0bMA66nkmJfqp3rqG+aS8vRqsNzVOPR+/G72vsa68sKKLn6MlUueaza28pxwqKGTTuBlz//YA9m/cx8Iafo5nsbH1vAUUodL9pMuPSDlOwbh0mmwFvdQMet5dAQOBz1VGrxDNi4rWsX7GSvHU7SLTZqHc7cTlP/vLVkzbgarplplGvTaTcs5VJM39B/a419Lp6CN8sWo09KgpbZBuObVpOucONMb4H0+4YzLvPv0KDq+m+OLp5OY5+tzPm5o7oXWWokSkMHn4VSekx9B1ygFrFT3zmAHpF6XBW7jnVoMJofh/+QOMRf2/eDkZM/Ck+nZXdC75F00XToArq02KpT4rAnRyJp00Y+no35mInw5X2pDprSbJ340BgDX6vB00TBHxetJNmK1fUxr+D6noHXq8bTYjGdfu/2yYt4MN3/LmiN2DQB2ho8OB1e9ACHnZv2M21v7mGV+fnNxs/qCo/H6u1F+s2HyUzoRIlPJVBIwaT1CWcPoMPsGHtNqqOVNFn7CScSxZQH/Dh9wUQWgCfr/k5mIjkjsRGW9C8ATRNoPi8+AMaWsCP3y8w2Sx4XKXo3S78AQ2zLZYhN0zHa4pg5dubsehSyUoNR+9wUl/ffNwhV3UJRxvspMSYyC8P0HnoSDIy2hNz7QSqP91EzqTx2PVmorQyav16ug4bR4e0NPQTR9OwsZzBV/dCZ2uDr2wD+oQe3HTPjRRvWkPvq/qyrfAIxAyn/7AUXGX5+AOCNt2vJjfLyMfzFuI7aeep4UkMGXM1CenJ9BmSQ5k5g+zOMYQnp7Lnk28xxrRl4KhhJGdF0Kf/JlxxfencNoyodu3YMu8LBk1/gKx2blTXUNpVrqD4WB3dhl+LKQryaupBZ6ddsp296wua7QdFp8do1FHbUN+YiGsafq+3ccgHr5f6ij1UaLdy9fiJJEabECe1vLNoB3WjbmLwxHbE2FVUoxm94sPtduL1GhBCo+rYEfoNmURO/RccFVZU4cXt8uP1BpqPQ6VpVB6pJWfcJFxLPmffwQMUe1PJ1lZRWu4kQtHTbeRPiKgxkL9iHodNAQb1iMdgcOOsqz25NgD8Pi/Br1NPDWVVBob+ZDLLFq4g/xiM/sVdWOy1LDxSQ1uzgYZiB97jnyWPoxQRfS25o0vIW7WTgxXXMH7aLYQ5D7B/03L27FxHVJdrsPYTVFS7T7l+6cI477mZAoEA27dvJzU1laio87to8UJoydxMqqKiR+AVAoOqIjQNVBWzTofQAng0UBCoioIGaJqGTqfHpIAr4McvwKjq8GuNvSwA7aMT6Kpz8UV5LaqiYjs+4m1AC9AQ0DDpVLyBYPrT5LmCgkWvRxEazkAAUDCqCp7jCU91vzRcqdEkfboV5RS33epMVmx2KwF3Aw1ONyarFZ/Tid5iRfO40FnCMOoVhAjgrndhtNnQ6/X4XA5cLi+gYomIQC+81Dsa0JvtWK1mAl4nDQ5nsy8cRWfEFh6G5mnA6fRgDovAZFBw1tXiO+mIrepNWMOsoGkEvC5cLm/j3RURYfiddbjcPlS9CXuEHa+jFk9AwRYRjuL3UO+oR6BgtkdgMqi4HLVoOjMWixFN0/A56/H6NEy2MExGlYbaGoTejD3Mjgh4cdbVBbvmTzDZI7BYjAgtgLOuAXN4GDpVQfg91NU4MNmPb4ujFp9PA9WAzW7C6ag/5TRTeosdm9WM312P2yuwhtlRVYWAx4XHS+O2Cw23oxaP99RtpxMePH4NjCaM7RLwxZqotIAzKQY1KRJ/aTXGynosR2qwFFWhr/egegMYzFYs5sZ94XU2oBpN+J0N6Mw2NK/zeJIUbDWMtjBMBhVNaHgcdQi9BR0+vMfj0hnN6BU/Ho8fULCER6BXQWh+nPUuortdw8QRkcx7cT7N/gwVHVa7Ba/Xj0EVePxgC+6Lxr8jxWDGFmbD76zDE9BhUP14/Somo4Lb1bTXQDVasIfZEH4PDXUOVJMV1e8hoBjRqz4CGLFYTY0HX5fGyPt/y+GFL5J/pJ6GugbQGbFFhKGKAM66Ovwn/yEA0Z17EiuOsu9AOeawCMxmA0Lz01DrwGgPx6BT8DbU4XL7MYdHYjbpEQEfDQ4XljA7qiJwOWrxaXrCIsMbJzD3unE4GjDbIzAaFNyOOjxejcxJ99C2fiVffrW9+QFcZyAsMgKdquB3N+DxK1itFkTAS32dA6EaCIuIQFVp/JsXeqxWE5rPQ0NdPcawxtgQGq7aGvyqCZvdivC5qXfUo7PHk5WdwvY1eaeYNkzBZA/HqFfQNA13Qz0GswVPgxOj1Ybf3YBqtge33VlXz8l70mgLw2TUIfw+Gho8jfsGDREI0FDf0OT7wuX2Yw0LQ0FDC/hw1Tf/flENZuxhNrzOOrx+HUPv/C3aprdZueEwWTfMJKX2a1bnFdFQW0cAHbbwcPQquBw1zXqSofEHVcDjJHB84/VmOzarofH7QmfGFmbF72r8LjPa7JgMusbPSL0DvwaWsEj0aoCGmjrU43fheZ0nvjtB0ZswG8HlbN7zJYUmlLmZQk5mZs2aRXZ2NnfeeSeBQIDc3FxWr16N1Wrl888/Z9iwYecTe6s7VTKTYtSTZjKc5Z3nzmay0Sfazs6KcipO8WE6Z4qCL8ZGyfhs2ny5C3PxqX95SJepE6cwTnzkjk9kiaIg9Dp8kRa8MTa8sXbccWG424ShCIG+1oWxyonlaA3m4lp0Tg+qx984Z9Qlog9ry7DrR3JoxSccOHSKaSIuJcVI1shRlG1YRFnN5TjGjoLRZgdvwykPttLpKCRk59Kzq42Vny2i3qWR1Otqwmu2sCe/8lIHJ10APk3jiyMlFyaZSUlJ4eOPP6ZPnz58/PHH/OpXv2LZsmW88847LFu2jFWrVp1X8K3tVMmMHtBfgffN6eLCsN3YB+fuYvzL9rTavELSBaCAYjFCQAO/hqFzHPqUKAhoCI8foWmoVhNqlBVdXBhquAW/x4/P4cZf3YD/WA3+ozVQ40L1NM46LttbkqQfE00ISqurL8ys2RUVFSQkJACwcOFCbrzxRtLT07nzzjv5+9//HlJdjz32GI8//niTZfHx8ZSUlACNUyc8/vjjvPbaa1RXV9O/f39efPFFMjMzQw27CT/gP7+za5eEIdyMwajDmXeo2TUQP3jHL7RsvC9cXJ4HdqMeQ1osqtmAGmPD3Kd946zgvgBavQdPuQNFr6IY9aCq+J0eAlUNBPaUEKhwIJxeNLePs97uIkmS9CMQSl9LyMlMfHw8u3btIjExkUWLFvHSSy8B4HQ60elCH2wuMzOTr776Kvj8+3U888wzPPfcc7z11lukp6czZ84crrnmGvbu3UtYWFhI69F3GYGqv3Cnli4GXaQFNSqD8J8Z8WwpwF8WASKM0GcBanrtxKV3UnKiOFHUElC8qHYDhg6x6BOjQK8HEUA4PWgOd9NHg7exDmFHaLEgjt9JcMrNC2WbRZN/Gt8eAKUKRa0C/CgmA8aMBPRJcahRXcBgQxF+fAer8e4rA52KVuNEa7Ccdi1qNBBNCwcqlCRJ+uHT/D5Y90GLyoaczPzsZz9jypQpJCYmoigK11xzDQDr1q0jIyMj1OrQ6/XBnp7vE0Lwwgsv8Mgjj3D99dcD8PbbbxMfH8+7777L3XffHdJ6Pp33OvawM3dTXRGUAFXefBYVbmBzaS3Tu44j2RZNhNGG2oJTZwGhsan8IGXOWiJNdjpFJBBnjUC5BElNQGgccpSxu+oIu6sOk19XSpXbgdWg0DHSTBuLFavBSE5sGl2j22JQ9Qih4fC5qHDVUe6qo8JdR6XbQa2ngYDQqHD5KKpzY9LZaR8WR2p4GxKtUWgI/IEAelVHRlQKyfaYZlvs0wKUuWopcVbT4HMjhKDe56bYWU1JQzUlzhrKXbWARoLNQNswM0aditVgol98Z7KiO6ASCxhonDRK1zidtyRJkhSyekcdgzpdoGTmscceIysri8OHD3PjjTdiMjWOuaHT6Zg9e3ao1bF//36SkpIwmUz079+fJ598kg4dOlBQUEBJSQmjRo0KljWZTMELjk+XzHg8Hjye764ir6urAyCzjY7w8B/C714dkEG/+A68s3spnxd+REBo6BWVaHMYMeYwwowWrHoTNoMJndJ4l5VA4A74yK8tocxVi91gZm+tm+XFXiw6IzpVpWNEAj3bdCAzuh3J9mhUpXWGIRJCUOaqZXXxHtaV7KPIUY6GQKeo+LUAsZYw+ia25ZaMAcRZI7EZTKTYYrEZTMHrnFq6nhpvA8UN1Rypr6SwroxDjmNsr96FqqjoFBVFgbyK5diNFsIMZgTg9ntx+r24/I13I+hVFVVRUQC7wUyCNYrsNrEk2jrTxhKBWWcgxhxGG0sERt3pPkJy1ANJkqTzUWdu+TH7vG/NPh9ffPEFTqeT9PR0SktLmTNnDnv27GHnzp3s3buXwYMHc/ToUZKSkoLvueuuuygsLOTLL788ZZ2nug4HaNEFRFcaTWhUuh1UuBzUeBood9VS5XFQ73XT4PfQ4HM3Jjpq423hJp2BdmFtGN2uJ7GWcDwBH0WOchxeF06/h+2VRWwuO0idz8WodjlMSOtLjDm8RT0+3yeEoNxVx7rSfSw7sp1qTz0ev48YSzgDE7qQFh6PTlXQKTriLBEk2aLQqRcn0dSExmFHBQdqS6jxNA6eZtGbsOpNhBnNRB9PUmz60BIpSZIkqXWduIGn1e5mCuXC3vvvv7/FZU/W0NBAx44d+d3vfseAAQMYPHgwx44dIzExMVjmF7/4BYcPH2bRokWnrONUPTNt27b9QSYz3xdqTnrygfrE+/0iwIGaYl7Z8SUVrjoGJWZwa5eriDK1bObneq+L/x5cw5eFmwgzWhmb2ot4ayTRJjudIhOP945c+iThdPvrcohNkiRJCi2ZaVFf+PPPP9+iFSuKcl7JjM1mIzs7m/379zNp0iQASkpKmiQzZWVlxMfHn7YOk8kUPPX1Y3K+B+ET7zcoejKiUnhm8HT2VB/h7d3LeOCbfxJvjWR0u570T0jHZmg63HxA0yh11rD86A5WFe/GqOqZlTORnDZpGFX9ZZkgXI4xSZIkSeemRclMQUHzYa8vBI/Hw+7duxk6dChpaWkkJCSwZMkSevZsnHLd6/WyYsUKnn766YsSz4+VoiiYdAa6x7TnyYE/ZWvFIYoc5by1eynz939LmMFMRnQKVyVlsrOyiG+Ld3O0vpJkezQ3dhpMv/jOWPRGmTBIkiRJF8U5X6Xo9XopKCigY8eO6PXnVs1vfvMbJkyYQLt27SgrK2POnDnU1dUxffp0FEVh1qxZPPnkk3Tu3JnOnTvz5JNPYrVaufXWW881bCkEiqJg1hvpn5BOv/jOjE7txdbyfOp8LrZVHOLJjf8l0RrFiLbd6RiRQMeIBPSKTiYxkiRJ0kUVchbidDqZMWMGb7/9NgD79u2jQ4cO3H///SQlJYV0R9ORI0e45ZZbqKiooE2bNgwYMIC1a9eSmpoKwO9+9ztcLhf33ntvcNC8xYsXhzzGjHT+FEUh3GhhaHImQgjGpvZCEwJFUVBRZAIjSZIkXTIh3800c+ZMVq1axQsvvMCYMWPYtm0bHTp04NNPP+XRRx9l8+bNFyrWcxLKBUSSJEmSJF0eWv0C4O/7+OOPee+99xgwYECTX+PdunXj4MGDoUcrSZIkSZJ0HkJOZsrLy4mLi2u2vKGh4bI81XCi4+nE4HmSJEmSJF3+Thy3W3ICKeRkpm/fvixYsIAZM2YA393i+vrrrzNw4MBQq7vgKisbp4Zv27btJY5EkiRJkqRQORwOIiIizlgm5GRm7ty5jBkzhl27duH3+/mf//kfdu7cyZo1a1ixYsU5B3uhREdHA1BUVHTWnSFdHCcGMjx8+LC8jukyINvj8iPb5PIi2+PSEELgcDiazAJwOiEnM4MGDWLVqlX89a9/pWPHjixevJhevXqxZs0asrOzzyngC0lVG+cXioiIkH+El5nw8HDZJpcR2R6XH9kmlxfZHhdfSzshzmmAmOzs7OCt2d/ndDqxWq3nUqUkSZIkSdI5CXla5GHDhnHkyJFmy9evX09OTk5rxCRJkiRJktRiIScz4eHhdO/enfnz5wOgaRqPPfYYQ4cOZeLEia0e4PkymUw8+uijP8r5mi5Xsk0uL7I9Lj+yTS4vsj0ufyEPmgfwyiuv8Jvf/IaJEydy6NAhioqKeOuttxg5cuSFiFGSJEmSJOm0zimZAXj44Yd5+umn0ev1LF++nEGDBrV2bJIkSZIkSWcV8mmm6upqbrjhBl5++WVeffVVpkyZwqhRo3jppZcuRHySJEmSJElnFHLPTHJyMmlpafzrX/8iLS0NgPfee497772XAQMGsGDBggsSqCRJkiRJ0qmE3DNzzz338M033wQTGYCbbrqJrVu34vV6WzU4SZIkSZKkswk5mfnjH/8YHIju+1JSUliyZEmrBNWaXnrpJdLS0jCbzfTu3ZuVK1de6pB+cObOnUvfvn0JCwsjLi6OSZMmsXfv3iZlhBA89thjJCUlYbFYGDZsGDt37mxSxuPxMGPGDGJjY7HZbEycOPGUwwBIoZs7dy6KojBr1qzgMtkmF9fRo0f56U9/SkxMDFarlZycHPLy8oKvy/a4uPx+P3/4wx9IS0vDYrHQoUMH/vznP6NpWrCMbJMriGiBrVu3ikAgEPz/mR6Xk/nz5wuDwSBef/11sWvXLjFz5kxhs9lEYWHhpQ7tB2X06NHizTffFDt27BBbtmwR48aNE+3atRP19fXBMk899ZQICwsTH3zwgdi+fbu46aabRGJioqirqwuWueeee0RycrJYsmSJ2LRpkxg+fLjo0aOH8Pv9l2KzfjDWr18v2rdvL7p37y5mzpwZXC7b5OKpqqoSqamp4vbbbxfr1q0TBQUF4quvvhIHDhwIlpHtcXHNmTNHxMTEiM8//1wUFBSI999/X9jtdvHCCy8Ey8g2uXK0KJlRFEWUlpYG/6+qqlAUJfg48VxV1QsabKj69esn7rnnnibLMjIyxOzZsy9RRD8OZWVlAhArVqwQQgihaZpISEgQTz31VLCM2+0WERER4pVXXhFCCFFTUyMMBoOYP39+sMzRo0eFqqpi0aJFF3cDfkAcDofo3LmzWLJkicjNzQ0mM7JNLq6HHnpIDBky5LSvy/a4+MaNGyfuuOOOJsuuv/568dOf/lQIIdvkStOi00wFBQW0adMm+P/8/HwKCgqCjxPP8/PzL2QnUki8Xi95eXmMGjWqyfJRo0axevXqSxTVj0NtbS3w3SSfBQUFlJSUNGkLk8lEbm5usC3y8vLw+XxNyiQlJZGVlSXb6zz86le/Yty4cc3GgJJtcnF9+umn9OnThxtvvJG4uDh69uzJ66+/HnxdtsfFN2TIEL7++mv27dsHwNatW/n222+59tprAdkmV5oWzc2Umpp6yv9fzioqKggEAsTHxzdZHh8fT0lJySWK6odPCMGDDz7IkCFDyMrKAgju71O1RWFhYbCM0WgkKiqqWRnZXudm/vz5bNq0iQ0bNjR7TbbJxZWfn8/LL7/Mgw8+yO9//3vWr1/P/fffj8lkYtq0abI9LoGHHnqI2tpaMjIy0Ol0BAIB/vKXv3DLLbcA8jNypTmniSb37t3L//7v/7J7924URSEjI4MZM2bQpUuX1o7vvCmK0uS5EKLZMqn13HfffWzbto1vv/222Wvn0hayvc7N4cOHmTlzJosXL8ZsNp+2nGyTi0PTNPr06cOTTz4JQM+ePdm5cycvv/wy06ZNC5aT7XHxvPfee/z73//m3XffJTMzky1btjBr1iySkpKYPn16sJxskytDyHcz/fe//yUrK4u8vDx69OhB9+7d2bRpE1lZWbz//vsXIsZzEhsbi06na5Ydl5WVNcu0pdYxY8YMPv30U5YtW0ZKSkpweUJCAsAZ2yIhIQGv10t1dfVpy0gtl5eXR1lZGb1790av16PX61mxYgV///vf0ev1wX0q2+TiSExMpFu3bk2Wde3alaKiIkB+Ri6F3/72t8yePZubb76Z7Oxspk6dygMPPMDcuXMB2SZXmpCTmd/97nc8/PDDrFmzhueee47nnnuO1atX8/vf/56HHnroQsR4ToxGI7179252u/iSJUvk1AutTAjBfffdx4cffsjSpUubjEEEkJaWRkJCQpO28Hq9rFixItgWvXv3xmAwNClTXFzMjh07ZHudgxEjRrB9+3a2bNkSfPTp04fbbruNLVu20KFDB9kmF9HgwYObDVewb9++4Gl7+Rm5+JxOZ7NhRnQ6XfDWbNkmV5hQrxi2WCxi//79zZbv27dPWCyWc78U+QI4cWv2P//5T7Fr1y4xa9YsYbPZxKFDhy51aD8ov/zlL0VERIRYvny5KC4uDj6cTmewzFNPPSUiIiLEhx9+KLZv3y5uueWWU97imJKSIr766iuxadMmcfXVV8tbHFvR9+9mEkK2ycW0fv16odfrxV/+8hexf/9+MW/ePGG1WsW///3vYBnZHhfX9OnTRXJycvDW7A8//FDExsaK3/3ud8Eysk2uHCEnM2PHjhVvvPFGs+VvvPGGGDVqVKsE1ZpefPFFkZqaKoxGo+jVq1fwdmGp9QCnfLz55pvBMpqmiUcffVQkJCQIk8kkrrrqKrF9+/Ym9bhcLnHfffeJ6OhoYbFYxPjx40VRUdFF3pofrpOTGdkmF9dnn30msrKyhMlkEhkZGeK1115r8rpsj4urrq5OzJw5U7Rr106YzWbRoUMH8cgjjwiPxxMsI9vkyhHy3EyvvPIKf/rTn5gyZQoDBgwAYO3atbz//vs8/vjjJCUlBctOnDixtTqQJEmSJEmSTinkZOZUUxmcsmJFIRAInFNQkiRJkiRJLRVyMiNJkiRJknQ5CfluJkmSJEmSpMuJTGYkSZIkSbqiyWRGkiRJkqQrWouTmSNHjlzIOCRJkiRJks5Ji5OZrKws/vWvf13IWCRJkiRJkkLW4mTmySef5Fe/+hU33HADlZWVFzImSZIkSZKkFmtxMnPvvfeydetWqquryczM5NNPP72QcUmSdIVTFIWPP/641eobNmwYs2bNarX6QnHo0CEURWHLli0ALF++HEVRqKmpuSTxSJLUlD6UwmlpaSxdupR//OMf3HDDDXTt2hW9vmkVmzZtatUAJUm6MAKBAEOHDiUxMZEPPvgguLy2tpasrCymT5/OnDlzzrn+4uJioqKiWiPUy86gQYMoLi4mIiLiUociSRIhJjMAhYWFfPDBB0RHR3Pdddc1S2YkSboy6HQ63n77bXJycpg3bx633XYbADNmzCA6Opo//elP51V/QkJCa4R5WTIajT/o7ZOkK01It2a//vrrZGdnExUVxY4dO3jiiSd49NFHmzwkSbpydO7cmblz5zJjxgyOHTvGJ598wvz583n77bcxGo2nfV/79u154oknuPXWW7Hb7SQlJfG///u/Tcp8/zTTO++8g91uZ//+/cHXZ8yYQXp6Og0NDQDs2rWLa6+9FrvdTnx8PFOnTqWioqLF27J161aGDx9OWFgY4eHh9O7dm40bNwZfX7VqFbm5uVitVqKiohg9ejTV1dUALFq0iCFDhhAZGUlMTAzjx4/n4MGDp13XyaeZ3nrrLSIjI/nyyy/p2rUrdrudMWPGUFxcHHyP3+/n/vvvD67joYceYvr06UyaNKnF2yhJ0qm1OJkZM2YMDz30EP/4xz/48MMPadOmzYWMS5Kki2TGjBn06NGDadOmcdddd/GnP/2JnJycs77v2WefpXv37mzatImHH36YBx54gCVLlpyy7LRp07j22mu57bbb8Pv9LFq0iFdffZV58+Zhs9koLi4mNzeXnJwcNm7cyKJFiygtLWXKlCkt3o7bbruNlJQUNmzYQF5eHrNnz8ZgMACwZcsWRowYQWZmJmvWrOHbb79lwoQJwfnjGhoaePDBB9mwYQNff/01qqoyefJkNE1r8fqdTid//etf+de//sU333xDUVERv/nNb4KvP/3008ybN48333yTVatWUVdX16rXFEnSj1pLp9ceOXKkOHz48IWZu1uSpEtq9+7dAhDZ2dnC5/OdtXxqaqoYM2ZMk2U33XSTGDt2bPA5ID766KPg86qqKpGSkiJ++ctfivj4eDFnzpzga3/84x/FqFGjmtR3+PBhAYi9e/cKIYTIzc0VM2fOPG1MYWFh4q233jrla7fccosYPHjwWbfrhLKyMgGI7du3CyGEKCgoEIDYvHmzEEKIZcuWCUBUV1cLIYR48803BSAOHDgQrOPFF18U8fHxwefx8fHi2WefDT73+/2iXbt24rrrrmtxXJIknVqLe2aWLFlCSkrKBUmoJEm6tN544w2sVisFBQUtHiBz4MCBzZ7v3r37tOWjoqL45z//ycsvv0zHjh2ZPXt28LW8vDyWLVuG3W4PPjIyMgDOeLrn+x588EF+/vOfM3LkSJ566qkm7zvRM3M6Bw8e5NZbb6VDhw6Eh4eTlpYGQFFRUYvWDWC1WunYsWPweWJiImVlZUDjRdWlpaX069cv+LpOp6N3794trl+SpNOT0xlI0o/cmjVreP755/nkk08YOHAgd955J0KIc6pLUZQzvv7NN9+g0+k4duxY8FoZAE3TmDBhAlu2bGny2L9/P1dddVWL1v3YY4+xc+dOxo0bx9KlS+nWrRsfffQRABaL5YzvnTBhApWVlbz++uusW7eOdevWAeD1elu0biB4SusERVGa7ceT98+57mdJkpqSyYwk/Yi5XC6mT5/O3XffzciRI/m///s/NmzYwKuvvnrW965du7bZ8xO9KaeyevVqnnnmGT777DPCw8OZMWNG8LVevXqxc+dO2rdvT6dOnZo8bDZbi7cnPT2dBx54gMWLF3P99dfz5ptvAtC9e3e+/vrrU76nsrKS3bt384c//IERI0bQtWvX4IXBrSUiIoL4+HjWr18fXBYIBNi8eXOrrkeSfqxkMiNJP2KzZ89G0zSefvppANq1a8ff/vY3fvvb33Lo0KEzvnfVqlU888wz7Nu3jxdffJH333+fmTNnnrKsw+Fg6tSpzJgxg7Fjx/Luu+/yn//8h/fffx+AX/3qV1RVVXHLLbewfv168vPzWbx4MXfccUfwIt0zcblc3HfffSxfvpzCwkJWrVrFhg0b6Nq1KwAPP/wwGzZs4N5772Xbtm3s2bOHl19+mYqKCqKiooiJieG1117jwIEDLF26lAcffDCEvdgyM2bMYO7cuXzyySfs3buXmTNnUl1dfdbeLEmSzk4mM5L0I7VixQpefPFF3nrrrSa9H7/4xS8YNGjQWU83/frXvyYvL4+ePXvyxBNP8Le//Y3Ro0efsuzMmTOx2Ww8+eSTAGRmZvL0009zzz33cPToUZKSkli1ahWBQIDRo0eTlZXFzJkziYiIQFXP/jWl0+morKxk2rRppKenM2XKFMaOHcvjjz8ONPbYLF68mK1bt9KvXz8GDhzIJ598gl6vR1VV5s+fT15eHllZWTzwwAM8++yzoezKFnnooYe45ZZbmDZtGgMHDsRutzN69GjMZnOrr0uSfmwUIU/aSpIUovbt2zNr1qxLNr3AD4GmaXTt2pUpU6bwxBNPXOpwJOmKJofvlSRJuggKCwtZvHgxubm5eDwe/vGPf1BQUMCtt956qUOTpCuePM0kSZJ0EaiqyltvvUXfvn0ZPHgw27dv56uvvgpe1yNJ0rmTp5kkSZIkSbqiyZ4ZSZIkSZKuaDKZkSRJkiTpiiaTGUmSJEmSrmgymZEkSZIk6YomkxlJkiRJkq5oMpmRJEmSJOmKJpMZSZIkSZKuaDKZkSRJkiTpivb/AVC2UHIYOljKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It needs 129 GIGABYTES of RAM to do this!!!!!\n"
     ]
    }
   ],
   "source": [
    "# I tried it >:)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    " \n",
    "plt.title(\"Sheep Image\")\n",
    "plt.xlabel(\"X pixel scaling\")\n",
    "plt.ylabel(\"Y pixels scaling\")\n",
    " \n",
    "image = mpimg.imread(\"/home/soulmou/Downloads/jupyter_stupid.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(\"It needs 129 GIGABYTES of RAM to do this!!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b605ec-c36b-4213-a2c4-a4fff4748304",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<h2 style=\"color:green;\">Code block 4</h2>\n",
    "<p>\n",
    "    This block of code makes a new linear form for the interactions between Attack, Defense, Speed, the Legendary status, the Special Defence and the Special attack of a Pokemon, and how those predictors affect the HP of the PokÃ©mon (which is the outcome)\n",
    "    <br/>\n",
    "    <br/>\n",
    "    Then, it fits the new model made and gives a summary of it.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "490a288a-72a2-40fe-801d-76c41bafae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.4670944211577768\n",
      "'Out of sample' R-squared: 0.0024853435077556935\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13c6d6-78f1-429a-9850-5e902dc19969",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<h2 style=\"color:green;\">Code block 5</h2>\n",
    "<p>\n",
    "    This block of code gives both the in-sample and out-of-sample \\(R^2\\) (in the same way as code block 3), which are respectively 0.47 and 0.002.\n",
    "    <br/>\n",
    "    <br/>\n",
    "    The in-sample \\(R^2\\) is quite high, as this model explains 47% of the variance in the in-sample dataset.\n",
    "    <br/>\n",
    "    However, the out-of-sample \\(R^2\\) is significantly lower, as this model would explain only 0.2% of the variance in the out-of-sample dataset.\n",
    "    <br/>\n",
    "    This is a sign of overfitting.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7be8dc-24aa-4e9b-91a2-8f3daa99d62d",
   "metadata": {},
   "source": [
    "Here is a summary of my discussion with ChatGPT for question 5:\n",
    "\n",
    "1. **Splitting Data (train/test)**:\n",
    "   - We discussed how the **`train_test_split`** function from **`sklearn.model_selection`** randomly splits the dataset into training and testing sets.\n",
    "   - The randomness is controlled by a seed (e.g., `np.random.seed(130)`) to ensure reproducibility.\n",
    "\n",
    "2. **Linear Regression with `smf.ols`**:\n",
    "   - You asked about **`smf.ols`**, a function from **`statsmodels.formula.api`** used to perform **Ordinary Least Squares (OLS)** linear regression using **R-style formulas** (e.g., `'HP ~ Attack + Defense'`).\n",
    "   - We discussed the purpose of the formula and the basic components of a regression model, including how the dependent variable and predictors are specified.\n",
    "\n",
    "3. **In-Sample vs Out-of-Sample \\(R^2\\)**:\n",
    "   - You provided a block of code calculating both **in-sample** and **out-of-sample \\(R^2\\)** values, and we discussed the implications of the results.\n",
    "   - In your case, the **in-sample \\(R^2\\)** was **0.47** (47%) and the **out-of-sample \\(R^2\\)** was **0.002** (0.2%).\n",
    "   - The large difference between these values suggested **overfitting**, where the model performs well on the training data but fails to generalize to the testing data.\n",
    "\n",
    "4. **Overfitting Explanation**:\n",
    "   - **Overfitting** occurs when the model becomes too complex, capturing noise or specific patterns in the training data that do not generalize well to unseen data.\n",
    "   - The low **out-of-sample \\(R^2\\)** suggests that the model is not robust and may require adjustments to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866a3c5-d1bc-4ee2-97ae-5a0d36887764",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question VI</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3797233-8934-4ea5-aba9-cc58c2b088ae",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<p>\n",
    "    To make the design matrix, the algorithm makes a row for every data point (here, for every pokemon). The first column is always a 1 (the intercept), then come the original predictors, and finally columns with the interaction terms, which makes new predictor variables.\n",
    "    For example, in model 4, we'd have the following:\n",
    "\\(\\begin{aligned}\n",
    "HP &\\sim \\beta_0 + \\beta_1 (\\text{Attack}) + \\beta_2 (\\text{Defense}) + \\beta_3 (\\text{Speed}) + \\beta_4 (\\text{Legendary}) \\\\\n",
    "&\\quad + \\beta_5 (\\text{Sp. Def}) + \\beta_6 (\\text{Sp. Atk}) \\\\\n",
    "&\\quad + \\beta_7 (\\text{Attack} \\times \\text{Defense}) + \\beta_8 (\\text{Attack} \\times \\text{Speed}) + \\ldots \\\\\n",
    "&\\quad + \\beta_{9} (\\text{Attack} \\times \\text{Legendary}) + \\ldots \\\\\n",
    "&\\quad + \\beta_{10} (\\text{Attack} \\times \\text{Defense} \\times \\text{Speed}) + \\ldots \\\\\n",
    "&\\quad + \\text{(all higher-order interactions up to six-way)}.\n",
    "\\end{aligned}\\)\n",
    "<br/>\n",
    "<br/>\n",
    "        The condition number of a design matrix provides a measure of multicollinearity in a model fit. The bigger it is the larger the degree of multicollinearity.\n",
    "    <br/><br/>\n",
    "    Multicollinearity is not good for generalizability as it means that predictors are highly correlated, which implies that they carry redundant information. This leads to multiple solutions fitting the data just as well as one another, creating instability in the fitted model.\n",
    "    <br/><br/>\n",
    "    Centering and scaling makes interpreting the predictions on the data's original scale more complicated but it is indispensable to get the true evaluation of multicollinearity in the model fit.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9f81a30-c620-4fd1-a47f-8a3331a6d2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:26:37</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     23:26:37     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        23:26:37   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "model3_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6259caa-f104-40aa-8cbf-736bda0af8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:26:45</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     23:26:45     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        23:26:45   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb1acc88-5aaf-4770-9c22-1b3f9e3829b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a3bb9fd-031f-4e2a-8449-b2637b885248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.665  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as the condition number was very bad to start with\n",
    "model4_fit.summary().tables[-1]  # Cond. No. is 12,000,000,000,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2573b-5409-45fe-b987-b496c4600a57",
   "metadata": {},
   "source": [
    "Here is the ChatGPT summary for thsi question:\n",
    "\n",
    "### **1. Linear Form Specification (`model4_linear_form`)**\n",
    "- The model was specified as:\n",
    "    model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "- This formula uses the `*` operator, which generates both **main effects** and all possible **interaction terms**:\n",
    "  - **Main Effects**: `Attack`, `Defense`, `Speed`, `Legendary`, `Sp. Def`, `Sp. Atk`\n",
    "  - **Interaction Terms**: Includes two-way interactions (e.g., `Attack:Defense`), three-way interactions (e.g., `Attack:Defense:Speed`), up to six-way interactions involving all predictors.\n",
    "\n",
    "### **2. Creation of New Predictor Variables in the Design Matrix**\n",
    "- The design matrix (`model4_spec.exog`) is constructed by expanding the formula:\n",
    "  - It includes:\n",
    "    - An **intercept** column.\n",
    "    - Columns for **main effects** (original variables).\n",
    "    - Columns for all possible **interaction terms**.\n",
    "- This results in a design matrix with many columns, representing both the original variables and their interactions.\n",
    "\n",
    "- For example, with the specified formula:\n",
    "  - **Main effects**: 6 columns (one for each original variable).\n",
    "  - **Interaction terms**: Includes 2-way, 3-way, up to 6-way interactions, resulting in a total of **64 columns**.\n",
    "\n",
    "### **3. Multicollinearity in the Design Matrix**\n",
    "- **Multicollinearity** occurs when two or more predictor variables (or their interactions) are highly correlated.\n",
    "- This is problematic because:\n",
    "  - **Coefficient Instability**: The regression model struggles to assign unique coefficients to correlated predictors, leading to large standard errors and unstable estimates.\n",
    "  - **Overfitting**: The model may fit the training data very well (high in-sample \\(R^2\\)) but perform poorly on new data (low out-of-sample \\(R^2\\)) due to over-reliance on specific patterns in the training data.\n",
    "\n",
    "### **4. Generalizability Issues Due to Multicollinearity**\n",
    "- When predictor variables are highly correlated, the model becomes sensitive to small changes in the training data, which affects its ability to generalize to unseen data.\n",
    "- This was observed in your model where the in-sample \\(R^2\\) was high (indicating a good fit on the training data) but the out-of-sample \\(R^2\\) was significantly lower, suggesting overfitting.\n",
    "\n",
    "### **Key Takeaways**\n",
    "- The complex interactions in the design matrix can lead to **multicollinearity**, which harms the modelâ€™s generalization capability.\n",
    "- Addressing multicollinearity (e.g., through feature selection, regularization, or removing highly correlated predictors) can improve the out-of-sample performance of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8fd3c-57e4-4114-9604-575d837e5e62",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question VII</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00f472c7-de9a-4df3-b1bf-d4db9e1ce561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:27:00</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     23:27:00     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        23:27:00   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d04f27bd-3d5d-43e1-8c7e-e064ad8512e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488651776\n"
     ]
    }
   ],
   "source": [
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "362e3258-12e1-4b35-bb0c-fb6de27c3260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:27:05</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     23:27:05     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        23:27:05   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "803272ae-cc81-4f2e-aa96-441bc584d2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.2957246042708008\n"
     ]
    }
   ],
   "source": [
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f3c7ff2-20dc-4ceb-8832-6ccd21ca8422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:27:10</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Tue, 12 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     23:27:10     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Tue, 12 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        23:27:10   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "008349f0-aa09-4f99-9335-9d3d19b383c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.3505538923467793\n"
     ]
    }
   ],
   "source": [
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "915ee36b-22d4-40c2-9153-e05eb12c5042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "645b8022-45e3-4e71-bcad-f94db9d87443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea921da8-5808-4ae6-98ca-c33d4ba055f0",
   "metadata": {},
   "source": [
    "<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "<p>\n",
    "    To make the linear form of model 5, we saw that the large amount of interactions overfit model 4, making unsuitable for generalization. Thus, we took the elements used in model 4 and arranged them as additive terms, just like was done in model 3.\n",
    "</p>\n",
    "<br/>\n",
    "<p>\n",
    "    Then, in model 6, we try to weed out the elements that don't account for a large variance in the model and turn the important values into binary indicator variables. \n",
    "    <br/><br/>\n",
    "    For example, whether or not a PokÃ©mon comes from generation 3 is not likely to help the prediction (the p-value for a null-hypothesis of no change is 0.555).<br/>\n",
    "    Meanwhile, whether a PokÃ©mon comes from generation 5 seems to have a big impact (this variable has a p-value of 0.004, which provides strong evidence against the null hypothesis, so we can reject it).\n",
    "    <br/><br/>\n",
    "    Thus, by looking at the potential effect of each variable of model 5, we can take the values that have a large effect on the model and use them for model 6.\n",
    "</p>\n",
    "<br/>\n",
    "<p>\n",
    "    In model 6, we can see that the in-sample and out-of-sample \\(R^{2}\\) are high enough, at 33% and 29% respectively.\n",
    "    <br/>\n",
    "    For model 7, we want to raise the variance explained by said model if possible.\n",
    "    <br/>\n",
    "    It is to do that that we change some predictor additions into interactions.\n",
    "    <br/>\n",
    "    Looking at model 7, it does work, as the in-sample \\(R^{2}\\) goes up to 37% and the out-of-sample \\(R^{2}\\) goes up to 35% (the out-of-sample \\(R^{2}\\) is also closer to the in-sample one here).\n",
    "    <br/>\n",
    "    Thus, model 7 is better at predictions.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89ee1d-c34b-4777-b7ec-b6c369384b3f",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question VIII</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bac11a29-f365-4242-b071-15c34c6e9c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "In Sample R^2=%{x}<br>Out of Sample R^2=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "opacity": 0.7,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.22928528900444856,
          0.27527605820160417,
          0.29065195173234537,
          0.23936516963979348,
          0.20040970769019428,
          0.2871441890207317,
          0.2101727663353572,
          0.27241869447023614,
          0.21236750441935848,
          0.33507582016024573,
          0.30742461627657347,
          0.23043762911881605,
          0.22809214796683064,
          0.2392555520840487,
          0.26171739293554686,
          0.3369919224360959,
          0.23479592066289723,
          0.23926373123857114,
          0.2689240135998098,
          0.26609724353637276,
          0.3387557605277699,
          0.3098244097479037,
          0.39053500882092407,
          0.3590989002310402,
          0.25098206526738454,
          0.20010764523240698,
          0.27728679016047464,
          0.22722624592382512,
          0.3561263251617377,
          0.24046270015385074,
          0.23052703729205992,
          0.22867814649417906,
          0.20207678977546006,
          0.3419778639285267,
          0.2515367033034879,
          0.2156443939307261,
          0.283409413855195,
          0.2748014552003891,
          0.1931696632034362,
          0.16934163280674253,
          0.31578749764997804,
          0.20557395822978575,
          0.24203793292348152,
          0.2114641746267485,
          0.24114442869124486,
          0.3235299160280948,
          0.22526472919536866,
          0.180752919467693,
          0.2881697734421641,
          0.21940956653649735,
          0.22668795189098456,
          0.4012351940835013,
          0.23597751863002958,
          0.20215159995131926,
          0.2748078424724004,
          0.25901631231702404,
          0.26840967803611593,
          0.19005401285368462,
          0.3141146795721135,
          0.24772775244744216,
          0.23531852560664634,
          0.21276312353002003,
          0.31804907839904584,
          0.2655451966960235,
          0.22503381882631313,
          0.25244658139492215,
          0.2080587773021636,
          0.30527821159326607,
          0.3103053734880722,
          0.19647604327914958,
          0.3267247439435227,
          0.22998932494711088,
          0.27742535414497227,
          0.19709991675603578,
          0.24713154871742027,
          0.2621146216795982,
          0.3185324336156984,
          0.21387792287837915,
          0.34512176765374813,
          0.27852709276151555,
          0.22136804673248656,
          0.3067877289678912,
          0.2695688786591586,
          0.1789497904766818,
          0.30788635122728636,
          0.26215561381113117,
          0.2765870811404315,
          0.2513493662911689,
          0.24604676177589724,
          0.23899533977796172,
          0.284659114675997,
          0.2915195603163526,
          0.2892693930398351,
          0.2575711469215517,
          0.256362990597937,
          0.20524941104435834,
          0.2994242893946826,
          0.24582061766661756,
          0.1830224875677129,
          0.1875135726509808
         ],
         "xaxis": "x",
         "y": [
          0.2510255340771597,
          0.21166506621229011,
          0.19214911310006588,
          0.2079319816440951,
          0.2783590625181383,
          0.1917456896020346,
          0.274636346684876,
          0.21259312622680598,
          0.2681213486465644,
          0.16911870225385706,
          0.17636016863765877,
          0.25270049846379844,
          0.22531204597930085,
          0.23832760688807514,
          0.20927426815444453,
          0.15505739493373114,
          0.2280597502759897,
          0.2401082905535498,
          0.20021812970165795,
          0.2039608968528146,
          0.16430266445674327,
          0.17823790009250803,
          0.13993137992892116,
          0.1502008172391436,
          0.20966293212772638,
          0.25525782903797833,
          0.18675915149245095,
          0.2438869623906634,
          0.14366978620525012,
          0.2239456668545948,
          0.22970705823894505,
          0.2512777814149337,
          0.2801183377103685,
          0.15633381601800697,
          0.2233429106838983,
          0.26132686348620854,
          0.1950460948844094,
          0.21211845496258944,
          0.2927481498763722,
          0.27362327046155094,
          0.17688671795300545,
          0.2651090873582982,
          0.22403161238694821,
          0.2690980266356213,
          0.21169147232793634,
          0.1685279376352079,
          0.24543109904356175,
          0.2920147010324061,
          0.1983417169546246,
          0.258617704224443,
          0.20822236515759615,
          0.1250365128385773,
          0.24540901084727068,
          0.2784087073126502,
          0.20908469791384246,
          0.229113326929476,
          0.21284931816672678,
          0.29430777683798676,
          0.1772252704733421,
          0.23496801490055133,
          0.235432977449627,
          0.2666379627087948,
          0.15623360661298463,
          0.2096468159245828,
          0.24397185313833553,
          0.22500466644674902,
          0.2645024107855396,
          0.17989476474402888,
          0.16137248120788872,
          0.2831894604302761,
          0.17372201874558652,
          0.25140015753991385,
          0.21119610162002006,
          0.26844198180842405,
          0.2363962419767781,
          0.22378649444488313,
          0.12863874936742375,
          0.25802713203846855,
          0.1620783247411892,
          0.21120232002508585,
          0.23726367502698467,
          0.17411910149691495,
          0.2111565867905508,
          0.2980774935243089,
          0.17651306556459062,
          0.20913671431583564,
          0.19634064064739645,
          0.21389705756647837,
          0.23848229388385125,
          0.23709548848060974,
          0.19647554251720722,
          0.19282610559600083,
          0.19896724543514888,
          0.22386286319604368,
          0.22014546878786434,
          0.2754869488784208,
          0.19580083497616185,
          0.2304663194325173,
          0.29083850781323534,
          0.2824614300305342
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "dash": "dash"
         },
         "mode": "lines",
         "name": "y=x",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "In-Sample vs Out-of-Sample RÂ² Performance"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          1
         ],
         "title": {
          "text": "In Sample R^2"
         },
         "type": "linear"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -0.05555555555555555,
          1.0555555555555556
         ],
         "title": {
          "text": "Out of Sample R^2"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"38affecf-426f-4abc-b7f3-e69392d0f374\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"38affecf-426f-4abc-b7f3-e69392d0f374\")) {                    Plotly.newPlot(                        \"38affecf-426f-4abc-b7f3-e69392d0f374\",                        [{\"hovertemplate\":\"In Sample R^2=%{x}\\u003cbr\\u003eOut of Sample R^2=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"opacity\":0.7,\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.22928528900444856,0.27527605820160417,0.29065195173234537,0.23936516963979348,0.20040970769019428,0.2871441890207317,0.2101727663353572,0.27241869447023614,0.21236750441935848,0.33507582016024573,0.30742461627657347,0.23043762911881605,0.22809214796683064,0.2392555520840487,0.26171739293554686,0.3369919224360959,0.23479592066289723,0.23926373123857114,0.2689240135998098,0.26609724353637276,0.3387557605277699,0.3098244097479037,0.39053500882092407,0.3590989002310402,0.25098206526738454,0.20010764523240698,0.27728679016047464,0.22722624592382512,0.3561263251617377,0.24046270015385074,0.23052703729205992,0.22867814649417906,0.20207678977546006,0.3419778639285267,0.2515367033034879,0.2156443939307261,0.283409413855195,0.2748014552003891,0.1931696632034362,0.16934163280674253,0.31578749764997804,0.20557395822978575,0.24203793292348152,0.2114641746267485,0.24114442869124486,0.3235299160280948,0.22526472919536866,0.180752919467693,0.2881697734421641,0.21940956653649735,0.22668795189098456,0.4012351940835013,0.23597751863002958,0.20215159995131926,0.2748078424724004,0.25901631231702404,0.26840967803611593,0.19005401285368462,0.3141146795721135,0.24772775244744216,0.23531852560664634,0.21276312353002003,0.31804907839904584,0.2655451966960235,0.22503381882631313,0.25244658139492215,0.2080587773021636,0.30527821159326607,0.3103053734880722,0.19647604327914958,0.3267247439435227,0.22998932494711088,0.27742535414497227,0.19709991675603578,0.24713154871742027,0.2621146216795982,0.3185324336156984,0.21387792287837915,0.34512176765374813,0.27852709276151555,0.22136804673248656,0.3067877289678912,0.2695688786591586,0.1789497904766818,0.30788635122728636,0.26215561381113117,0.2765870811404315,0.2513493662911689,0.24604676177589724,0.23899533977796172,0.284659114675997,0.2915195603163526,0.2892693930398351,0.2575711469215517,0.256362990597937,0.20524941104435834,0.2994242893946826,0.24582061766661756,0.1830224875677129,0.1875135726509808],\"xaxis\":\"x\",\"y\":[0.2510255340771597,0.21166506621229011,0.19214911310006588,0.2079319816440951,0.2783590625181383,0.1917456896020346,0.274636346684876,0.21259312622680598,0.2681213486465644,0.16911870225385706,0.17636016863765877,0.25270049846379844,0.22531204597930085,0.23832760688807514,0.20927426815444453,0.15505739493373114,0.2280597502759897,0.2401082905535498,0.20021812970165795,0.2039608968528146,0.16430266445674327,0.17823790009250803,0.13993137992892116,0.1502008172391436,0.20966293212772638,0.25525782903797833,0.18675915149245095,0.2438869623906634,0.14366978620525012,0.2239456668545948,0.22970705823894505,0.2512777814149337,0.2801183377103685,0.15633381601800697,0.2233429106838983,0.26132686348620854,0.1950460948844094,0.21211845496258944,0.2927481498763722,0.27362327046155094,0.17688671795300545,0.2651090873582982,0.22403161238694821,0.2690980266356213,0.21169147232793634,0.1685279376352079,0.24543109904356175,0.2920147010324061,0.1983417169546246,0.258617704224443,0.20822236515759615,0.1250365128385773,0.24540901084727068,0.2784087073126502,0.20908469791384246,0.229113326929476,0.21284931816672678,0.29430777683798676,0.1772252704733421,0.23496801490055133,0.235432977449627,0.2666379627087948,0.15623360661298463,0.2096468159245828,0.24397185313833553,0.22500466644674902,0.2645024107855396,0.17989476474402888,0.16137248120788872,0.2831894604302761,0.17372201874558652,0.25140015753991385,0.21119610162002006,0.26844198180842405,0.2363962419767781,0.22378649444488313,0.12863874936742375,0.25802713203846855,0.1620783247411892,0.21120232002508585,0.23726367502698467,0.17411910149691495,0.2111565867905508,0.2980774935243089,0.17651306556459062,0.20913671431583564,0.19634064064739645,0.21389705756647837,0.23848229388385125,0.23709548848060974,0.19647554251720722,0.19282610559600083,0.19896724543514888,0.22386286319604368,0.22014546878786434,0.2754869488784208,0.19580083497616185,0.2304663194325173,0.29083850781323534,0.2824614300305342],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"line\":{\"dash\":\"dash\"},\"mode\":\"lines\",\"name\":\"y=x\",\"x\":[0,1],\"y\":[0,1],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"In Sample R^2\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Out of Sample R^2\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"In-Sample vs Out-of-Sample R\\u00b2 Performance\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('38affecf-426f-4abc-b7f3-e69392d0f374');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define the linear model formula based on your pokeaman dataset\n",
    "linear_form = 'HP ~ Attack * Defense + Speed * Q(\"Sp. Atk\")'\n",
    "\n",
    "# Number of repetitions for evaluation\n",
    "reps = 100\n",
    "in_sample_Rsquared = []\n",
    "out_of_sample_Rsquared = []\n",
    "\n",
    "# Loop to create, fit, and evaluate models multiple times\n",
    "for i in range(reps):\n",
    "    # Perform train-test split without using a fixed random seed\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=int(0.5 * pokeaman.shape[0]))\n",
    "    \n",
    "    # Fit the linear model on the training set\n",
    "    model_fit = smf.ols(formula=linear_form, data=pokeaman_train).fit()\n",
    "    \n",
    "    # Calculate in-sample R^2\n",
    "    in_sample_r2 = model_fit.rsquared\n",
    "    in_sample_Rsquared.append(in_sample_r2)\n",
    "    \n",
    "    # Calculate out-of-sample R^2\n",
    "    y_true = pokeaman_test.HP\n",
    "    y_pred = model_fit.predict(pokeaman_test)\n",
    "    \n",
    "    # Handle cases where correlation could be NaN\n",
    "    corr_coef = np.corrcoef(y_true, y_pred)[0, 1] if not np.isnan(np.corrcoef(y_true, y_pred)[0, 1]) else 0\n",
    "    out_sample_r2 = corr_coef ** 2\n",
    "    out_of_sample_Rsquared.append(out_sample_r2)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"In Sample R^2\": in_sample_Rsquared,\n",
    "    \"Out of Sample R^2\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Visualize the results using Plotly\n",
    "fig = px.scatter(results_df, x=\"In Sample R^2\", y=\"Out of Sample R^2\",\n",
    "                 title=\"In-Sample vs Out-of-Sample RÂ² Performance\",\n",
    "                 labels={\"x\": \"In-Sample RÂ²\", \"y\": \"Out-of-Sample RÂ²\"},\n",
    "                 opacity=0.7)\n",
    "\n",
    "# Add a reference line y=x to assess generalizability\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='y=x', line=dict(dash='dash')))\n",
    "\n",
    "# Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbb7f8-ef3d-4ce8-87b7-508bf37c0a29",
   "metadata": {},
   "source": [
    "<p>\n",
    "    In each iteration of the for loop, we compare the in-sample and out-of-sample \\(R^2\\) of the model we are using. Every iteration of the for loop uses a different sample, which means the in-sample and out-of-sample data points are different in-between iterations.\n",
    "</p>\n",
    "<p>\n",
    "    If the out-of-sample \\(R^2\\) is larger than the in-sample \\(R^2\\), this is a sign of the sample not being representative of the population, or it could be by simple chance.\n",
    "</p>\n",
    "<p>\n",
    "    However, we want our model to work well whatever the sample is. What this code does is it compares the \\(R^2\\) in-sample and out-of-sample to find how stably fitting our model is.\n",
    "</p>\n",
    "<p>\n",
    "    From the graph given by the code, we can see a high negative correlation for the out-of-sample \\(R^2\\) compared to the in-sample \\(R^2\\).\n",
    "    <br/>\n",
    "    In other words, the larger the in-sample R^2 is, the lower the out-of-sample \\(R^2\\) is.\n",
    "    <br/>\n",
    "    This negative correlation suggests that the model may be overfitting\n",
    "    <br/><br/>\n",
    "    These datapoints find the \\(x=y\\) line at (0.25,0.25)\n",
    "    <br/>\n",
    "    This means that, on average, our linear form explains 25% of the variability in this dataset.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6155b0-c669-4874-9810-f31639ace08a",
   "metadata": {},
   "source": [
    "Here is the summary of my discussion with ChatGPT for Question 8:\n",
    "\n",
    "1. **Adapting the Loop for \"In-Sample\" and \"Out-of-Sample\" \\( R^2 \\) Evaluation**:\n",
    "    - We wrote a Python for loop to evaluate the performance of a regression model on different random splits of the dataset.\n",
    "    - The loop repeatedly fits a model on a training subset and tests it on a different testing subset without using a fixed random seed for each iteration.\n",
    "    - For each iteration, we recorded the in-sample \\( R^2 \\) (training performance) and the out-of-sample \\( R^2 \\) (testing performance).\n",
    "    - We used these results to visualize the stability of the model's performance across different splits using a scatter plot.\n",
    "\n",
    "2. **Purpose of This Demonstration**:\n",
    "    - The primary goal of this demonstration was to assess the stability and generalizability of the regression model.\n",
    "    - By comparing in-sample and out-of-sample \\( R^2 \\) values across multiple iterations, we could evaluate whether our model was overfitting (performing well on training data but poorly on new, unseen data).\n",
    "\n",
    "3. **Interpreting the Results**:\n",
    "    - If the out-of-sample \\( R^2 \\) is consistently lower than the in-sample \\( R^2 \\), it indicates overfitting. However, if the out-of-sample \\( R^2 \\) is sometimes higher, this could suggest that the training sample isn't fully representative of the overall population, or it could be due to randomness in the sampling process.\n",
    "    - We observed a negative correlation between in-sample and out-of-sample \\( R^2 \\) values in the scatter plot.\n",
    "        - When the model had a high in-sample \\( R^2 \\), it tended to have a lower out-of-sample \\( R^2 \\), indicating overfitting.\n",
    "    - The data points intersected the \\( x=y \\) line around (0.25, 0.25), suggesting that on average, our model explains about 25% of the variance in both training and testing datasets.\n",
    "\n",
    "4. **Conclusions**:\n",
    "    - The negative correlation observed in the scatter plot implies that as the model fits the training data better (high in-sample \\( R^2 \\)), it becomes less effective at generalizing to new data (lower out-of-sample \\( R^2 \\)).\n",
    "    - This pattern suggests the model might be too complex for the data, capturing noise rather than meaningful patterns, which undermines its predictive power on unseen data.\n",
    "    - The fact that our model explains only around 25% of the variance highlights potential limitations in the model's specifications or the predictors used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b4916-fc81-4d5e-910e-be361ace9a40",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Question IX</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f25fb3f7-31db-4215-830a-29d987c30508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.36642028450259767 (original)\n",
      "'In sample' R-squared:     0.5726118179916574 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363388299076 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a45e936f-76b2-4abb-b56d-6cd4b7746453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.36642028450259767 (original)\n",
      "'In sample' R-squared:     0.3904756578094537 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915489191068 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "579cd87a-c9f1-47cf-a488-d4ad52e2a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.38662360281118496 (original)\n",
      "'In sample' R-squared:     0.44338805177272833 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.19328585342762092 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ebd81f8-b16b-49ac-bf03-6cd720040f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.38662360281118496 (original)\n",
      "'In sample' R-squared:     0.335172798241148 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.2626269017880005 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e17b1-b116-4967-bd4b-44e0eefe4b9a",
   "metadata": {},
   "source": [
    "<p>\n",
    "With these blocks of code, what we are trying to see is how much (or how little) a model trained on certain generations can predict the ones that come after it. In other words, if a model is trained on generation 1, can it predict the HP of PokÃ©mon in generation 5 or 6?\n",
    "</p>\n",
    "<br/>\n",
    "<p>\n",
    "    In the first block of code, we train model 7 on PokÃ©mon from generation 1.<br/>\n",
    "    The model 7 trained from data from all generations explains avout 37% of the variance both in-sample and out-of sample.\n",
    "    <br/>\n",
    "    However, even though the model 7 trained only on generation 1, has a much higher in-sample \\(R^2\\) (explaining 57% of the variance of HP in generation 1 PokÃ©mon), it has an overwhelmingly smaller out-of-sample \\(R^2\\) of 11%.\n",
    "    <br/><br/>\n",
    "    This increase in in-sample \\(R^2\\) and drop in out-of-sample R^2 implies that model7 fits gen 1 data better but also that it overfits, that it does not generalize well in-between generations.\n",
    "</p>\n",
    "<br/><br/>\n",
    "<p>\n",
    "    The second block of code trains the model on generations 1 through 5 and tries to predict generation 6.\n",
    "    <br/>\n",
    "    The in-sample \\(R^2\\) of generations 1 through 5 is 0.39, which is actually a little higher than the original 0.37.\n",
    "    <br/>\n",
    "    The out-of-sample \\(R^2\\) is of 0.23, so when trained on generations 1 through 5, model 7 accounts for 23% of the variance of the HP in generation 6's PokÃ©mon.\n",
    "    <br/>This implies that there is still overfitting here.\n",
    "</p>\n",
    "<p>\n",
    "    The third block of code trains model 6 on generation 1 and tries to predict other generations.\n",
    "    <br/>\n",
    "    The in-sample \\(R^2\\) of generation 1 is 44%. This is a lot higher than the original model 6's 33%.\n",
    "    <br/>\n",
    "    The out-of-sample \\(R^2\\), however is of 29%, once again suggesting overfitting when model 6 is trained on generation 1.\n",
    "</p>\n",
    "<p>\n",
    "    The last block of code trains model 6 on generations 1 through 5 and tries to predict generation 6.\n",
    "    <br/>\n",
    "    The in-sample \\(R^2\\) of generations 1 through 5 is 0.33, which on par with the original in-sample \\(R^2\\).\n",
    "    <br/>\n",
    "    The out-of-sample \\(R^2\\) of the gen1-5 trained model is of 0.26, so when trained on generations 1 through 5, model 6 accounts for 26% of the variance of the HP in generation 6's PokÃ©mon.\n",
    "    <br/>This once again implies that there is still overfitting here.\n",
    "</p>\n",
    "<br/><br/>\n",
    "<p>\n",
    "    From this, can we conclude that we cannot accurately predict a PokÃ©mon's HP if our model is trained on different generations? (this is a question to you, ChatGPT)\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
